{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "import datetime as dt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "AHBA_exprs = pd.read_csv('./AHBA_exprs_noNorm.csv', index_col=0).T\n",
    "#AHBA_exprs = pd.read_csv('./AHBA_exprs_SRS.csv', index_col=0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = AHBA_exprs.columns\n",
    "tf_names = [ tf.strip() for tf in open('./hs_hgnc_tfs.txt') ]\n",
    "tf_names = target_names[target_names.isin(tf_names)]\n",
    "tf_exprs = AHBA_exprs[tf_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ET_KWARGS = {\n",
    "    'n_jobs': 4,\n",
    "    'n_estimators': 1000,\n",
    "    'max_features': 'sqrt'\n",
    "}\n",
    "\n",
    "RF_KWARGS = {\n",
    "    'n_jobs': 4,\n",
    "    'n_estimators': 1000,\n",
    "    'max_features': 'sqrt'\n",
    "}\n",
    "SGBM_KWARGS = {\n",
    "    'learning_rate': 0.01,\n",
    "    'n_estimators': 1000,  # can be arbitrarily large\n",
    "    'max_features': 0.1,\n",
    "    'subsample': 0.9\n",
    "}\n",
    "\n",
    "for k, t_name in enumerate(target_names):\n",
    "    if t_name in tf_names:\n",
    "        select_idx = tf_names.isin([t_name])\n",
    "        train_x = tf_exprs.loc[:, ~select_idx]\n",
    "    else:\n",
    "        train_x = tf_exprs\n",
    "    train_y = AHBA_exprs[t_name]\n",
    "\n",
    "    #et = ExtraTreesRegressor(random_state=666, **ET_KWARGS)\n",
    "    #et.fit(train_x, train_y)\n",
    "    #links_df = pd.DataFrame({'TF': train_x.columns, 'importance': et.feature_importances_})\n",
    "\n",
    "    rf = RandomForestRegressor(random_state=666, **RF_KWARGS)\n",
    "    rf.fit(train_x, train_y)\n",
    "    links_df = pd.DataFrame({'TF': train_x.columns, 'importance': rf.feature_importances_})\n",
    "\n",
    "    #gbm = GradientBoostingRegressor(random_state=666, **SGBM_KWARGS)\n",
    "    #gbm.fit(train_x, train_y)\n",
    "    #links_df = pd.DataFrame({'TF': train_x.columns, 'importance': gbm.feature_importances_*gbm.n_estimators})\n",
    "\n",
    "\n",
    "    links_df['target'] = t_name\n",
    "    clean_links_df = links_df[links_df.importance > 0].sort_values(by='importance', ascending=False)\n",
    "    clean_links_df = clean_links_df[['TF', 'target', 'importance']]\n",
    "    clean_links_df.to_pickle(f'./2.grn/{t_name}_grn.pkl')\n",
    "    if k % 10 == 0:\n",
    "        print(dt.datetime.now(), clean_links_df.shape[0])\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "990dc0a4dfa05ebda672dfcd39271a4a2e9840c833a961469b52bed8d7792dce"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
