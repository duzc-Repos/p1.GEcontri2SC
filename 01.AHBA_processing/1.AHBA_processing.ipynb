{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import loompy as lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './'\n",
    "\n",
    "file_probe_annot = os.path.join(path, \"probes.csv\")\n",
    "probe_annot = pd.read_csv(file_probe_annot, sep=\",\", header=None)\n",
    "probe_annot.columns = [\"probe_id\", \"probe_name\", \"gene_id\", \"gene_symbol\", \"gene_name\", \"entrez_id\", \"chromosome\"]\n",
    "\n",
    "## load re-annotation information (from abagen package)\n",
    "file_probe_reannot = os.path.join(path, \"reannotated.csv.gz\")\n",
    "probe_reannot = pd.read_csv(file_probe_reannot)\n",
    "\n",
    "\n",
    "file_rawdata = './rawdata.pkl'\n",
    "if os.path.exists(file_rawdata):\n",
    "    probe_annot, probe_reannot, data = pickle.load(open(file_rawdata, 'rb'))\n",
    "else:\n",
    "    data = {}\n",
    "    for subj in [10021, 14380, 15697, 12876, 15496, 9861]:\n",
    "        file_microarray = os.path.join(path, f\"microarray/normalized_microarray_donor{subj}/MicroarrayExpression.csv\")\n",
    "        file_noise = os.path.join(path, f\"./microarray/normalized_microarray_donor{subj}/PACall.csv\")\n",
    "        file_annot = os.path.join(path, f\"microarray/normalized_microarray_donor{subj}/SampleAnnot.csv\")\n",
    "\n",
    "        data[subj] = {\"exprs\" : pd.read_csv(file_microarray, header=None, index_col=0),\n",
    "                      \"noise\" : pd.read_csv(file_noise, header=None, index_col=0),\n",
    "                      \"annot\" : pd.read_csv(file_annot)}\n",
    "        data[subj][\"annot\"].index = data[subj][\"exprs\"].columns\n",
    "    pickle.dump([probe_annot, probe_reannot, data], open(file_rawdata, 'wb'))\n",
    "\n",
    "##########################################\n",
    "## 1. Filtering samples and probes\n",
    "##########################################\n",
    "## 1.0 re-annotaion\n",
    "probe_reannot_filter1 = pd.merge(probe_reannot[['probe_name', 'gene_symbol', 'entrez_id']], \n",
    "                                 probe_annot[[\"probe_name\", \"probe_id\"]], \n",
    "                                 on=\"probe_name\", how=\"left\").set_index(\"probe_id\").dropna(subset=[\"entrez_id\"])\n",
    "probe_reannot_filter1.loc[:, \"entrez_id\"] = probe_reannot_filter1[\"entrez_id\"].astype(int)\n",
    "\n",
    "## 1.1 remove sample in Brainstem(BS) and Cerebellum(CB), select reannotated probes\n",
    "index_probe_keep = probe_reannot_filter1.index\n",
    "for subj in data:\n",
    "    index_sample_keep   = ~data[subj]['annot'].slab_type.isin([\"BS\", \"CB\"])\n",
    "    data[subj]['exprs'] = data[subj]['exprs'].loc[index_probe_keep, index_sample_keep]\n",
    "    data[subj]['noise'] = data[subj]['noise'].loc[index_probe_keep, index_sample_keep]\n",
    "    data[subj]['annot'] = data[subj]['annot'].loc[index_sample_keep, :]\n",
    "\n",
    "## 1.2 probe: intensity-based filtering (IBF)\n",
    "threshold = 0.5\n",
    "signal_level, n_sample = np.zeros(probe_reannot_filter1.shape[0]), 0\n",
    "for subj in data:\n",
    "    signal_level += data[subj]['noise'].sum(axis=1)\n",
    "    n_sample += data[subj]['noise'].shape[1]\n",
    "index_probe_keep_IBF = (signal_level / n_sample ) > threshold\n",
    "\n",
    "probe_reannot_filter2 = probe_reannot_filter1.loc[index_probe_keep_IBF, :]\n",
    "for subj in data:\n",
    "    data[subj]['exprs'] = data[subj]['exprs'].loc[index_probe_keep_IBF, :]\n",
    "    data[subj]['noise'] = data[subj]['noise'].loc[index_probe_keep_IBF, :]\n",
    "\n",
    "## 1.3 probe: select representative probe (DS method)\n",
    "region_exprs = [ data[subj]['exprs'].groupby(data[subj]['annot'].structure_id, axis=1).mean().T.rank() for subj in data ]  # sample * probe\n",
    "\n",
    "## calc DS score for each probes\n",
    "ds_score = np.zeros(probe_reannot_filter2.shape[0])\n",
    "for i in range(len(region_exprs)-1):\n",
    "    exprs1_zscore = (region_exprs[i] - region_exprs[i].mean(axis=0)) / region_exprs[i].std(axis=0)\n",
    "    for j in range(i+1, len(region_exprs)):\n",
    "        exprs2_zscore = (region_exprs[j] - region_exprs[j].mean(axis=0)) / region_exprs[j].std(axis=0)\n",
    "        samples = np.intersect1d(exprs1_zscore.index, exprs2_zscore.index)\n",
    "        ds_score += (exprs1_zscore.loc[samples, :] * exprs2_zscore.loc[samples, :]).sum(axis=0) / (len(samples) - 1)\n",
    "ds_score /= sum(range(len(region_exprs)))\n",
    "\n",
    "## select probe\n",
    "max_ds_idx = pd.DataFrame([ds_score, probe_reannot_filter2.entrez_id]).T.reset_index().set_index(keys=[\"entrez_id\", \"probe_id\"]).groupby(\"entrez_id\").idxmax()[\"Unnamed 0\"]\n",
    "index_probe_keep_DS =  pd.Index(max_ds_idx.apply(lambda x:x[1]).values)\n",
    "probe_reannot_filter3 = probe_reannot_filter2.loc[index_probe_keep_DS, :]\n",
    "for subj in data:\n",
    "    data[subj]['exprs'] = data[subj]['exprs'].loc[index_probe_keep_DS, :]\n",
    "    data[subj]['noise'] = data[subj]['noise'].loc[index_probe_keep_DS, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15746, 622) (15746, 622)\n",
      "(15746, 401) (15746, 401)\n",
      "(15746, 362) (15746, 362)\n",
      "(15746, 295) (15746, 295)\n",
      "(15746, 329) (15746, 329)\n",
      "(15746, 739) (15746, 739)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15746, 2748)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exprs = []\n",
    "sample_donor = []\n",
    "sample_annot = []\n",
    "for subj in data:\n",
    "    a = data[subj]['exprs'][data[subj]['noise'].astype(bool)].fillna(0).astype(np.float32)\n",
    "    print(a.shape, data[subj]['exprs'].shape)\n",
    "    exprs.append( data[subj]['exprs'][data[subj]['noise'].astype(bool)].fillna(0).astype(np.float32) )\n",
    "    sample_donor.append(np.repeat(subj, data[subj]['exprs'].shape[1]))\n",
    "    sample_annot.append(data[subj]['annot'].values[:, [4, 5, 7, 8, 9, 10, 11, 12]])\n",
    "exprs = np.concatenate(exprs, axis=1)\n",
    "sample_donor = np.concatenate(sample_donor, axis=0)\n",
    "sample_annot = np.concatenate(sample_annot, axis=0)\n",
    "\n",
    "row_attrs = {\"Gene\" : probe_reannot_filter3['gene_symbol'].values,}\n",
    "col_attrs = {\"CellID\" :  np.arange(exprs.shape[1])}\n",
    "lp.create(\"AHBA_exprs_noNorm.loom\", exprs, row_attrs, col_attrs)\n",
    "\n",
    "exprs = pd.DataFrame(exprs)\n",
    "exprs.index = probe_reannot_filter3['gene_symbol'].values\n",
    "exprs.to_csv('AHBA_exprs_noNorm.csv')\n",
    "exprs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1.5 SRS normalization\n",
    "for subj in data:\n",
    "    # sample normalization across genes: SRS\n",
    "    quantile = data[subj]['exprs'].quantile([0.25, 0.5, 0.75], axis=0)\n",
    "    scale_iqr = quantile.loc[0.75, :] - quantile.loc[0.25, :]/1.35\n",
    "    scale_robust_sigmoid = 1 / (1 + np.exp(-(data[subj]['exprs'] - quantile.loc[0.5, :])/scale_iqr))\n",
    "\n",
    "    # gene unitu across samples:\n",
    "    dat_range = scale_robust_sigmoid.max(axis=1)-scale_robust_sigmoid.min(axis=1)\n",
    "    gene_norm = ((scale_robust_sigmoid.T - scale_robust_sigmoid.min(axis=1))/dat_range).T\n",
    "\n",
    "    # set zero to background gene\n",
    "    data[subj]['exprs'] = gene_norm[data[subj]['noise'].astype(bool)].fillna(0).astype(np.float32)\n",
    "\n",
    "exprs = []\n",
    "for key in data:\n",
    "    exprs.append( data[key]['exprs'] )\n",
    "exprs = np.concatenate(exprs, axis=1)\n",
    "\n",
    "exprs = pd.DataFrame(exprs)\n",
    "exprs.index = probe_reannot_filter3['gene_symbol'].values\n",
    "exprs.to_csv('AHBA_exprs_SRS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "990dc0a4dfa05ebda672dfcd39271a4a2e9840c833a961469b52bed8d7792dce"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
